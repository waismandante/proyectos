{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo para obtener los datasets de la organización: 2.5318429470062256 segundos\n",
      "\n",
      "Conjuntos de datos que contienen 'Importación' en el título dentro de la organización 'Servicio Nacional de Aduanas':\n",
      "ID: 096c3946-657e-420f-ae74-2337c00b5ba2 - Nombre: Registro de Importación 2024\n",
      "ID: d1a42e81-b874-4964-9b3d-74dc0f813eae - Nombre: Registro de Importación 2023\n",
      "ID: 2538ffb0-402f-4fbf-a706-5f7fbe271670 - Nombre: Registro de Importación 2022\n",
      "ID: ad202066-18e6-42dd-b70b-1991774656b5 - Nombre: Registro de Importación 2021\n",
      "ID: 6ed59525-1ff2-44d9-a26f-0e9078ca45d0 - Nombre: Registro de Importación 2020\n",
      "ID: 3d7848c1-b1f1-46a0-b147-8e9f83767433 - Nombre: Registro de Importación 2019\n",
      "ID: c2f1008d-b84f-49cd-ba27-16cb7e842f38 - Nombre: Registros de Importación 2018\n",
      "ID: 15fa27c6-efc7-4960-9833-56d36dacd303 - Nombre: Registros de Importación 2007\n",
      "ID: 8d7d1ddc-e56f-4ead-b401-748d38cf028e - Nombre: Registros de Importación 2008\n",
      "ID: f97ffcdb-4200-416d-8498-b2156f9fe3a8 - Nombre: Registros de Importación 2009\n",
      "ID: ed97ca95-b74e-4182-850a-d23e515d3b23 - Nombre: Registros de Importación 2010\n",
      "ID: 8bc9a2ee-6645-44cc-87d0-34375769be18 - Nombre: Registros de Importación 2011\n",
      "ID: 26d3b5b5-649b-4ea6-a9c4-6b11274dfcde - Nombre: Registros de Importación 2012\n",
      "ID: 179f0a6b-0898-4060-8433-5c10a7553af0 - Nombre: Registros de Importación 2013\n",
      "ID: 097803f9-333b-4cc4-a07a-a1d0bc15fbdd - Nombre: Registros de Importación 2014\n",
      "ID: da62712a-eecd-451c-9015-fd8803a45407 - Nombre: Registros de Importación 2015\n",
      "ID: 5cfcd596-d425-4d07-8044-75d70c893325 - Nombre: Registros de Importación 2016\n",
      "ID: b3ce7942-bf2c-4ab9-ba25-ebc730396b6d - Nombre: Registros de Importación 2017\n",
      "Tiempo para filtrar los datasets: 0.0010046958923339844 segundos\n"
     ]
    }
   ],
   "source": [
    "#esto agarra todos los datasets que hay en servicio nacional aduanas y para obtener los ID que queremos\n",
    "\n",
    "\n",
    "import ckanapi\n",
    "import time\n",
    "\n",
    "# Crear una instancia del RemoteCKAN para conectarse a la API\n",
    "ckan = ckanapi.RemoteCKAN('https://datos.gob.cl')\n",
    "\n",
    "try:\n",
    "    # Establecer el ID de la organización objetivo\n",
    "    target_organization = 'servicio_nacional_de_aduanas'\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Obtener los datasets de la organización \"Servicio Nacional de Aduanas\"\n",
    "    org_datasets = ckan.action.organization_show(id=target_organization, include_datasets=True)['packages']\n",
    "    print(f\"Tiempo para obtener los datasets de la organización: {time.time() - start_time} segundos\")\n",
    "\n",
    "    # Filtrar los datasets que contienen la palabra clave \"Importación\"\n",
    "    keyword = \"Importación\"\n",
    "    print(f\"\\nConjuntos de datos que contienen '{keyword}' en el título dentro de la organización 'Servicio Nacional de Aduanas':\")\n",
    "    start_time = time.time()\n",
    "    for dataset in org_datasets:\n",
    "        if keyword.lower() in dataset['title'].lower():\n",
    "            print(f\"ID: {dataset['id']} - Nombre: {dataset['title']}\")\n",
    "    print(f\"Tiempo para filtrar los datasets: {time.time() - start_time} segundos\")\n",
    "\n",
    "except ckanapi.errors.NotFound as e:\n",
    "    print(f\"No se encontró el conjunto de datos: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al acceder a la API: {e}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado: datasets_importaciones\\Metadata Importaciones\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2024 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2024 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2024 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2024 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2024 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2024 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2024 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2024 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2024 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2024 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2024 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2024 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2024 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2024 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2024 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2024 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2024 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2024 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2024 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2024 5-5\n",
      "Archivo descargado: datasets_importaciones\\Metadata Importaciones\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - enero 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - abril 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 1-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 2-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 3-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 4-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 5-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - mayo 2023 6-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - junio 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - junio 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - junio 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - junio 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - junio 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - julio 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - julio 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - julio 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - julio 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - julio 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 1-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 2-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 3-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 4-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 5-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - agosto 2023 6-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - septiembre 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - septiembre 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - septiembre 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - septiembre 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - septiembre 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 1-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 2-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 3-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 4-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 5-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - octubre 2023 6-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - noviembre 2023 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - noviembre 2023 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - noviembre 2023 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - noviembre 2023 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - noviembre 2023 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones – diciembre 2023  1-5 \n",
      "Archivo descargado: datasets_importaciones\\Importaciones – diciembre 2023  2-5 \n",
      "Archivo descargado: datasets_importaciones\\Importaciones – diciembre 2023  3-5 \n",
      "Archivo descargado: datasets_importaciones\\Importaciones – diciembre 2023  4-5 \n",
      "Archivo descargado: datasets_importaciones\\Importaciones – diciembre 2023  5-5 \n",
      "Archivo descargado: datasets_importaciones\\Metadata Importaciones\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  1-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  2-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  3-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  4-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  5-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - Enero 2022  6-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2022 1-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2022 2-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2022 3-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2022 4-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - febrero 2022 5-5\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2022 1-6\n",
      "Archivo descargado: datasets_importaciones\\Importaciones - marzo 2022 2-6\n",
      "Error al acceder a la API: Response ended prematurely\n"
     ]
    }
   ],
   "source": [
    "#codigo para descargar 2022, 2023, 2024\n",
    "\n",
    "\n",
    "\n",
    "import ckanapi\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Crear una instancia del RemoteCKAN para conectarse a la API\n",
    "ckan = ckanapi.RemoteCKAN('https://datos.gob.cl')\n",
    "\n",
    "# Crear un directorio para almacenar los archivos descargados\n",
    "download_directory = 'datasets_importaciones'\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Establecer los IDs de los datasets objetivo\n",
    "    target_datasets = [\n",
    "        '096c3946-657e-420f-ae74-2337c00b5ba2',\n",
    "        'd1a42e81-b874-4964-9b3d-74dc0f813eae',\n",
    "        '2538ffb0-402f-4fbf-a706-5f7fbe271670'\n",
    "    ]\n",
    "    \n",
    "    for dataset_id in target_datasets:\n",
    "        # Obtener detalles del dataset\n",
    "        dataset_details = ckan.action.package_show(id=dataset_id)\n",
    "        resources = dataset_details['resources']\n",
    "        for resource in resources:\n",
    "            resource_url = resource['url']\n",
    "            # Asegurar un nombre de archivo seguro\n",
    "            resource_name = resource['name'].replace('/', '-').replace('\\\\', '-')\n",
    "            resource_path = os.path.join(download_directory, resource_name)\n",
    "            \n",
    "            response = requests.get(resource_url)\n",
    "            if response.status_code == 200:\n",
    "                # Guardar el archivo descargado\n",
    "                with open(resource_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"Archivo descargado: {resource_path}\")\n",
    "            else:\n",
    "                print(f\"Error al descargar el archivo: {resource_name}, URL: {resource_url}\")\n",
    "\n",
    "except ckanapi.errors.NotFound as e:\n",
    "    print(f\"No se encontró el conjunto de datos: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al acceder a la API: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo descargado: 2022\\Metadata Importaciones\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m resource_name \u001b[38;5;241m=\u001b[39m resource[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m resource_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_directory, resource_name)\n\u001b[1;32m---> 28\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Guardar el archivo descargado\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(resource_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:1040\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:1187\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1187\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(\n\u001b[0;32m   1189\u001b[0m     chunk, decode_content\u001b[38;5;241m=\u001b[39mdecode_content, flush_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m )\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\response.py:1129\u001b[0m, in \u001b[0;36mHTTPResponse._handle_chunk\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m   1127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left:\n\u001b[1;32m-> 1129\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[0;32m   1131\u001b[0m     returned_chunk \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[0;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ya veo que el codigo fallo con 2022 entonces hice uno para 2022\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Crear una instancia del RemoteCKAN para conectarse a la API\n",
    "ckan = ckanapi.RemoteCKAN('https://datos.gob.cl')\n",
    "\n",
    "# Crear un directorio para almacenar los archivos descargados\n",
    "download_directory = '2022'\n",
    "os.makedirs(download_directory, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # Establecer los IDs de los datasets objetivo\n",
    "    target_datasets = [\n",
    "        '2538ffb0-402f-4fbf-a706-5f7fbe271670'\n",
    "    ]\n",
    "    \n",
    "    for dataset_id in target_datasets:\n",
    "        # Obtener detalles del dataset\n",
    "        dataset_details = ckan.action.package_show(id=dataset_id)\n",
    "        resources = dataset_details['resources']\n",
    "        for resource in resources:\n",
    "            resource_url = resource['url']\n",
    "            # Asegurar un nombre de archivo seguro\n",
    "            resource_name = resource['name'].replace('/', '-').replace('\\\\', '-')\n",
    "            resource_path = os.path.join(download_directory, resource_name)\n",
    "            \n",
    "            response = requests.get(resource_url)\n",
    "            if response.status_code == 200:\n",
    "                # Guardar el archivo descargado\n",
    "                with open(resource_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"Archivo descargado: {resource_path}\")\n",
    "            else:\n",
    "                print(f\"Error al descargar el archivo: {resource_name}, URL: {resource_url}\")\n",
    "\n",
    "except ckanapi.errors.NotFound as e:\n",
    "    print(f\"No se encontró el conjunto de datos: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al acceder a la API: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sirve para cambiar los nombres de los archivos para poder descargar, hay que tener cuidado de cambiar el año, tambien se podria poner como input de la funcion\n",
    "#esdecir, cambia los nombres de los archivos para poder extraer todos los archivos con una sola accion.\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "def rename_files(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        match = re.search(r'(.*2024\\s)(\\d+)', filename)\n",
    "        if match:\n",
    "            new_filename = f\"{match.group(1)}part{match.group(2).zfill(2)}\"\n",
    "            old_file = os.path.join(directory, filename)\n",
    "            new_file = os.path.join(directory, new_filename)\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed: {old_file} to {new_file}\")\n",
    "\n",
    "# Ejemplo de uso:\n",
    "directory_path = r'c:\\Users\\dwaisman\\Desktop\\Dante\\2024_camb_nombre'\n",
    "\n",
    "rename_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwaisman\\AppData\\Local\\Temp\\ipykernel_12292\\3860857051.py:30: DtypeWarning: Columns (44,45,46,52,98,107,108,131,139,149,151,153,155,159,162,166,168,169,170,172,173,176,177) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter=';')  # Asumiendo que los archivos .txt están delimitados por tabulaciones\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Leer el archivo .txt y convertirlo en un dataframe\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Asumiendo que los archivos .txt están delimitados por tabulaciones\u001b[39;00m\n\u001b[0;32m     31\u001b[0m dataframes\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo leído: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m \u001b[43m_stack_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\anaconda3\\envs\\mi_entorno\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2254\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[1;32m-> 2254\u001b[0m     \u001b[43mstacked\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rarfile\n",
    "import pandas as pd\n",
    "\n",
    "# Directorio donde están los archivos RAR descargados \n",
    "\n",
    "#Este codigo, sirve una vez que ya extrajimos los RAR y tenemos los txt en la carpeta, luego, leemos los txt y armamos un dataframe combinado\n",
    "#con todos los años.\n",
    "\n",
    "\n",
    "# Directorio donde se extraerán los archivos\n",
    "extracted_directory = '2023'\n",
    "os.makedirs(extracted_directory, exist_ok=True)\n",
    "\n",
    "\"\"\"# Extraer todos los archivos RAR\n",
    "for filename in os.listdir(download_directory):\n",
    "    print(\"ffff\")\n",
    "    print(filename)\n",
    "    if filename.endswith('.rar'):\n",
    "        rar_path = os.path.join(download_directory, filename)\n",
    "        with rarfile.RarFile(rar_path) as rar_ref:\n",
    "            rar_ref.extractall(extracted_directory)\n",
    "        print(f\"Archivo extraído: {filename}\")\n",
    "\"\"\"\n",
    "\n",
    "# Leer los archivos extraídos y convertirlos en dataframes\n",
    "dataframes = []\n",
    "for root, dirs, files in os.walk(extracted_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):  # Ajustar si los archivos tienen otra extensión\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Leer el archivo .txt y convertirlo en un dataframe\n",
    "            df = pd.read_csv(file_path, delimiter=';')  # Asumiendo que los archivos .txt están delimitados por tabulaciones\n",
    "            dataframes.append(df)\n",
    "            print(f\"Archivo leído: {file}\")\n",
    "\n",
    "# Opcional: Combinar todos los dataframes en uno solo\n",
    "if dataframes:\n",
    "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Mostrar información del dataframe combinado\n",
    "    print(combined_df.info())\n",
    "    print(combined_df.head())\n",
    "else:\n",
    "    print(\"No se encontraron archivos .txt para procesar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensión no soportada: Importaciones - abril 2022 1-5\n",
      "Extensión no soportada: Importaciones - abril 2022 2-5\n",
      "Extensión no soportada: Importaciones - abril 2022 3-5\n",
      "Extensión no soportada: Importaciones - abril 2022 4-5\n",
      "Extensión no soportada: Importaciones - abril 2022 5-5\n",
      "Extensión no soportada: Importaciones - agosto 2022 1-6\n",
      "Extensión no soportada: Importaciones - agosto 2022 2-6\n",
      "Extensión no soportada: Importaciones - agosto 2022 3-6\n",
      "Extensión no soportada: Importaciones - agosto 2022 4-6\n",
      "Extensión no soportada: Importaciones - agosto 2022 5-6\n",
      "Extensión no soportada: Importaciones - agosto 2022 6-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 1-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 2-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 3-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 4-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 5-6\n",
      "Extensión no soportada: Importaciones - Diciembre 2022 6-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  1-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  2-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  3-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  4-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  5-6\n",
      "Extensión no soportada: Importaciones - Enero 2022  6-6\n",
      "Extensión no soportada: Importaciones - febrero 2022 1-5\n",
      "Extensión no soportada: Importaciones - febrero 2022 2-5\n",
      "Extensión no soportada: Importaciones - febrero 2022 3-5\n",
      "Extensión no soportada: Importaciones - febrero 2022 4-5\n",
      "Extensión no soportada: Importaciones - febrero 2022 5-5\n",
      "Extensión no soportada: Importaciones - julio 2022 1-5\n",
      "Extensión no soportada: Importaciones - julio 2022 2-5\n",
      "Extensión no soportada: Importaciones - julio 2022 3-5\n",
      "Extensión no soportada: Importaciones - julio 2022 4-5\n",
      "Extensión no soportada: Importaciones - julio 2022 5-5\n",
      "Extensión no soportada: Importaciones - junio 2022 1-5\n",
      "Extensión no soportada: Importaciones - junio 2022 2-5\n",
      "Extensión no soportada: Importaciones - junio 2022 3-5\n",
      "Extensión no soportada: Importaciones - junio 2022 4-5\n",
      "Extensión no soportada: Importaciones - junio 2022 5-5\n",
      "Extensión no soportada: Importaciones - marzo 2022 1-6\n",
      "Extensión no soportada: Importaciones - marzo 2022 2-6\n",
      "Extensión no soportada: Importaciones - marzo 2022 3-6\n",
      "Extensión no soportada: Importaciones - marzo 2022 4-6\n",
      "Extensión no soportada: Importaciones - marzo 2022 5-6\n",
      "Extensión no soportada: Importaciones - marzo 2022 6-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 1-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 2-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 3-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 4-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 5-6\n",
      "Extensión no soportada: Importaciones - mayo 2022 6-6\n",
      "Extensión no soportada: Importaciones - noviembre 2022 1-5\n",
      "Extensión no soportada: Importaciones - noviembre 2022 2-5\n",
      "Extensión no soportada: Importaciones - noviembre 2022 3-5\n",
      "Extensión no soportada: Importaciones - noviembre 2022 4-5\n",
      "Extensión no soportada: Importaciones - noviembre 2022 5-5\n",
      "Extensión no soportada: Importaciones - octubre 2022 1-5\n",
      "Extensión no soportada: Importaciones - octubre 2022 2-5\n",
      "Extensión no soportada: Importaciones - octubre 2022 3-5\n",
      "Extensión no soportada: Importaciones - octubre 2022 4-5\n",
      "Extensión no soportada: Importaciones - octubre 2022 5-5\n",
      "Extensión no soportada: Importaciones - septiembre 2022 1-5\n",
      "Extensión no soportada: Importaciones - septiembre 2022 2-5\n",
      "Extensión no soportada: Importaciones - septiembre 2022 3-5\n",
      "Extensión no soportada: Importaciones - septiembre 2022 4-5\n",
      "Extensión no soportada: Importaciones - septiembre 2022 5-5\n",
      "Extensión no soportada: Metadata Importaciones\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArchivo leído: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Opcional: Combinar todos los dataframes en uno solo\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Mostrar información del dataframe combinado\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(combined_df\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\dwaisman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
